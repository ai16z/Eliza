####################################
#### Server & DB Configurations ####
####################################

# Cache Configs
CACHE_STORE=database # Defaults to database. Other available cache store: redis and filesystem
REDIS_URL=           # Redis URL - could be a local redis instance or cloud hosted redis. Also support rediss:// URLs
PGLITE_DATA_DIR=     #../pgLite/ if selecting a directory   --- or memory:// if selecting in memory

# Eliza Port Config
SERVER_PORT=3000

# Supabase Configuration
SUPABASE_URL=
SUPABASE_ANON_KEY=

###############################
#### Client Configurations ####
###############################

# Discord Configuration
DISCORD_APPLICATION_ID=
DISCORD_API_TOKEN=        # Bot token
DISCORD_VOICE_CHANNEL_ID= # The ID of the voice channel the bot should join (optional)

# Farcaster Neynar Configuration
FARCASTER_FID=                # The FID associated with the account your are sending casts from
FARCASTER_NEYNAR_API_KEY=     # Neynar API key: https://neynar.com/
FARCASTER_NEYNAR_SIGNER_UUID= # Signer for the account you are sending casts from. Create a signer here: https://dev.neynar.com/app
FARCASTER_DRY_RUN=false       # Set to true if you want to run the bot without actually publishing casts
FARCASTER_POLL_INTERVAL=120   # How often (in seconds) the bot should check for farcaster interactions (replies and mentions)

# Telegram Configuration
TELEGRAM_BOT_TOKEN=

# Twitter/X Configuration
TWITTER_DRY_RUN=false
TWITTER_USERNAME= # Account username
TWITTER_PASSWORD= # Account password
TWITTER_EMAIL=    # Account email
TWITTER_2FA_SECRET=
TWITTER_POLL_INTERVAL=120   # How often (in seconds) the bot should check for interactions
TWITTER_SEARCH_ENABLE=FALSE # Enable timeline search, WARNING this greatly increases your chance of getting banned
TWITTER_TARGET_USERS=       # Comma separated list of Twitter user names to interact with
TWITTER_RETRY_LIMIT=        # Maximum retry attempts for Twitter login
TWITTER_SPACES_ENABLE=false # Enable or disable Twitter Spaces logic
# Post Interval Settings (in minutes)
POST_INTERVAL_MIN= # Default: 90
POST_INTERVAL_MAX= # Default: 180
POST_IMMEDIATELY=  # Default: false
# Twitter action processing configuration
ACTION_INTERVAL=               # Interval in minutes between action processing runs (default: 5 minutes)
ENABLE_ACTION_PROCESSING=false # Set to true to enable the action processing loop
MAX_ACTIONS_PROCESSING=1       # Maximum number of actions (e.g., retweets, likes) to process in a single cycle. Helps prevent excessive or uncontrolled actions.
ACTION_TIMELINE_TYPE=foryou    # Type of timeline to interact with. Options: "foryou" or "following". Default: "foryou"
# CONFIGURATION FOR APPROVING TWEETS BEFORE IT GETS POSTED
TWITTER_APPROVAL_DISCORD_CHANNEL_ID=  # Channel ID for the Discord bot to listen and send approval messages
TWITTER_APPROVAL_DISCORD_BOT_TOKEN=   # Discord bot token (this could be a different bot token from DISCORD_API_TOKEN)
TWITTER_APPROVAL_ENABLED=             # Enable or disable Twitter approval logic #Default is false
TWITTER_APPROVAL_CHECK_INTERVAL=60000 # Default: 60 seconds

# WhatsApp Cloud API Configuration
WHATSAPP_ACCESS_TOKEN=         # Permanent access token from Facebook Developer Console
WHATSAPP_PHONE_NUMBER_ID=      # Phone number ID from WhatsApp Business API
WHATSAPP_BUSINESS_ACCOUNT_ID=  # Business Account ID from Facebook Business Manager
WHATSAPP_WEBHOOK_VERIFY_TOKEN= # Custom string for webhook verification
WHATSAPP_API_VERSION=v17.0     # WhatsApp API version (default: v17.0)

# Direct Client Setting
EXPRESS_MAX_PAYLOAD= # Default: 100kb

#######################################
#### Model Provider Configurations ####
#######################################

# OpenAI Configuration
OPENAI_API_KEY=         # OpenAI API key, starting with sk-
OPENAI_API_URL=         # OpenAI API Endpoint (optional), Default: https://api.openai.com/v1
SMALL_OPENAI_MODEL=     # Default: gpt-4o-mini
MEDIUM_OPENAI_MODEL=    # Default: gpt-4o
LARGE_OPENAI_MODEL=     # Default: gpt-4o
EMBEDDING_OPENAI_MODEL= # Default: text-embedding-3-small
IMAGE_OPENAI_MODEL=     # Default: dall-e-3
USE_OPENAI_EMBEDDING=   # Set to TRUE for OpenAI/1536, leave blank for local

# Eternal AI's Decentralized Inference API
ETERNALAI_URL=
ETERNALAI_MODEL=         # Default: "neuralmagic/Meta-Llama-3.1-405B-Instruct-quantized.w4a16"
ETERNALAI_CHAIN_ID=45762 #Default: "45762"
ETERNALAI_API_KEY=
ETERNALAI_LOG=false #Default: false

# Hyperbolic Configuration
HYPERBOLIC_API_KEY= # Hyperbolic API Key
HYPERBOLIC_MODEL=
IMAGE_HYPERBOLIC_MODEL=  # Default: FLUX.1-dev
SMALL_HYPERBOLIC_MODEL=  # Default: meta-llama/Llama-3.2-3B-Instruct
MEDIUM_HYPERBOLIC_MODEL= # Default: meta-llama/Meta-Llama-3.1-70B-Instruct
LARGE_HYPERBOLIC_MODEL=  # Default: meta-llama/Meta-Llama-3.1-405-Instruct

# Infera Configuration
INFERA_API_KEY=      # visit api.infera.org/docs to obtain an API key under /signup_user
INFERA_MODEL=        # Default: llama3.2:latest
INFERA_SERVER_URL=   # Default: https://api.infera.org/
SMALL_INFERA_MODEL=  #Recommended: llama3.2:latest
MEDIUM_INFERA_MODEL= #Recommended: mistral-nemo:latest
LARGE_INFERA_MODEL=  #Recommended: mistral-small:latest

# Venice Configuration
VENICE_API_KEY=      # generate from venice settings
SMALL_VENICE_MODEL=  # Default: llama-3.3-70b
MEDIUM_VENICE_MODEL= # Default: llama-3.3-70b
LARGE_VENICE_MODEL=  # Default: llama-3.1-405b
IMAGE_VENICE_MODEL=  # Default: fluently-xl

# Akash Chat API Configuration docs: https://chatapi.akash.network/documentation
AKASH_CHAT_API_KEY=          # Get from https://chatapi.akash.network/
SMALL_AKASH_CHAT_API_MODEL=  # Default: Meta-Llama-3-2-3B-Instruct
MEDIUM_AKASH_CHAT_API_MODEL= # Default: Meta-Llama-3-3-70B-Instruct
LARGE_AKASH_CHAT_API_MODEL=  # Default: Meta-Llama-3-1-405B-Instruct-FP8

# fal.ai Configuration
FAL_API_KEY=
FAL_AI_LORA_PATH=

# Web search API Configuration
TAVILY_API_KEY=

# Flow Blockchain Configuration
FLOW_ADDRESS=
FLOW_PRIVATE_KEY=  # Private key for SHA3-256 + P256 ECDSA
FLOW_NETWORK=      # Default: mainnet
FLOW_ENDPOINT_URL= # Default: https://mainnet.onflow.org

# ICP
INTERNET_COMPUTER_PRIVATE_KEY=
INTERNET_COMPUTER_ADDRESS=

# Aptos
APTOS_PRIVATE_KEY= # Aptos private key
APTOS_NETWORK=     # Must be one of mainnet, testnet

# MultiversX
MVX_PRIVATE_KEY= # Multiversx private key
MVX_NETWORK=     # must be one of mainnet, devnet, testnet

# NEAR
NEAR_WALLET_SECRET_KEY= # NEAR Wallet Secret Key
NEAR_WALLET_PUBLIC_KEY= # NEAR Wallet Public Key
NEAR_ADDRESS=
NEAR_SLIPPAGE=1
NEAR_RPC_URL=https://rpc.testnet.near.org
NEAR_NETWORK=testnet # or mainnet

# ZKsync Era Configuration
ZKSYNC_ADDRESS=
ZKSYNC_PRIVATE_KEY=

# Avail DA Configuration
AVAIL_ADDRESS=
AVAIL_SEED=
AVAIL_APP_ID=0
AVAIL_RPC_URL=wss://avail-turing.public.blastapi.io/ # (Default) Testnet: wss://avail-turing.public.blastapi.io/ | Mainnet: wss://avail-mainnet.public.blastapi.io/

# Marlin
TEE_MARLIN=                      # Set "yes" to enable the plugin
TEE_MARLIN_ATTESTATION_ENDPOINT= # Optional, default "http://127.0.0.1:1350"

# Ton
TON_PRIVATE_KEY= # Ton Mnemonic Seed Phrase Join With Empty String
TON_RPC_URL=     # ton rpc

# Sui
SUI_PRIVATE_KEY= # Sui Mnemonic Seed Phrase (`sui keytool generate ed25519`) , Also support `suiprivatekeyxxxx` (sui keytool export --key-identity 0x63)
SUI_NETWORK=     # must be one of mainnet, testnet, devnet, localnet

# Story
STORY_PRIVATE_KEY=  # Story private key
STORY_API_BASE_URL= # Story API base URL
STORY_API_KEY=      # Story API key
PINATA_JWT=         # Pinata JWT for uploading files to IPFS

# Cosmos
COSMOS_RECOVERY_PHRASE=  # 12 words recovery phrase (need to be in quotes, because of spaces)
COSMOS_AVAILABLE_CHAINS= # mantrachaintestnet2,cosmos  # Array of chains
# Cronos zkEVM
CRONOSZKEVM_ADDRESS=
CRONOSZKEVM_PRIVATE_KEY=

# Fuel Ecosystem (FuelVM)
FUEL_WALLET_PRIVATE_KEY=

# Tokenizer Settings
TOKENIZER_MODEL= # Specify the tokenizer model to be used.
TOKENIZER_TYPE=  # Options: tiktoken (for OpenAI models) or auto (AutoTokenizer from Hugging Face for non-OpenAI models). Default: tiktoken.

# Spheron
SPHERON_PRIVATE_KEY=
SPHERON_PROVIDER_PROXY_URL=
SPHERON_WALLET_ADDRESS=

# Stargaze NFT marketplace from Cosmos (You can use https://graphql.mainnet.stargaze-apis.com/graphql)
STARGAZE_ENDPOINT=

# GenLayer
GENLAYER_PRIVATE_KEY= # Private key of the GenLayer account to use for the agent in this format (0x0000000000000000000000000000000000000000000000000000000000000000)

####################################
#### Misc Plugin Configurations ####
####################################

# Intiface Configuration
INTIFACE_WEBSOCKET_URL=ws://localhost:12345

# API key for giphy from https://developers.giphy.com/dashboard/
GIPHY_API_KEY=

# OpenWeather
OPEN_WEATHER_API_KEY= # OpenWeather API key

# EchoChambers Configuration
ECHOCHAMBERS_API_URL=http://127.0.0.1:3333
ECHOCHAMBERS_API_KEY=testingkey0011
ECHOCHAMBERS_USERNAME=eliza
ECHOCHAMBERS_DEFAULT_ROOM=general
ECHOCHAMBERS_POLL_INTERVAL=60
ECHOCHAMBERS_MAX_MESSAGES=10

# Allora
ALLORA_API_KEY=    # Allora API key, format: UP-f8db7d6558ab432ca0d92716
ALLORA_CHAIN_SLUG= # must be one of mainnet, testnet. If not specified, it will use testnet by default

# Opacity zkTLS
OPACITY_TEAM_ID=f309ac8ae8a9a14a7e62cd1a521b1c5f
OPACITY_CLOUDFLARE_NAME=eigen-test
OPACITY_PROVER_URL=https://opacity-ai-zktls-demo.vercel.app

# AWS S3 Configuration Settings for File Upload
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=
AWS_S3_BUCKET=
AWS_S3_UPLOAD_PATH=

# Deepgram
DEEPGRAM_API_KEY=

# Verifiable Inference Configuration
VERIFIABLE_INFERENCE_ENABLED=false    # Set to false to disable verifiable inference
VERIFIABLE_INFERENCE_PROVIDER=opacity # Options: opacity

# TEE Configuration
# TEE_MODE options:
# - LOCAL: Uses simulator at localhost:8090 (for local development)
# - DOCKER: Uses simulator at host.docker.internal:8090 (for docker development)
# - PRODUCTION: No simulator, uses production endpoints
# Defaults to OFF if not specified
TEE_MODE=OFF        # LOCAL | DOCKER | PRODUCTION
WALLET_SECRET_SALT= # ONLY define if you want to use TEE Plugin, otherwise it will throw errors

# TEE Verifiable Log Configuration
VLOG= # true/false;  if you want to use TEE Verifiable Log, set this to "true"

# Galadriel Configuration
GALADRIEL_API_KEY=gal-* # Get from https://dashboard.galadriel.com/

# Venice Configuration
VENICE_API_KEY=      # generate from venice settings
SMALL_VENICE_MODEL=  # Default: llama-3.3-70b
MEDIUM_VENICE_MODEL= # Default: llama-3.3-70b
LARGE_VENICE_MODEL=  # Default: llama-3.1-405b
IMAGE_VENICE_MODEL=  # Default: fluently-xl

# Akash Chat API Configuration docs: https://chatapi.akash.network/documentation
AKASH_CHAT_API_KEY=          # Get from https://chatapi.akash.network/
SMALL_AKASH_CHAT_API_MODEL=  # Default: Meta-Llama-3-2-3B-Instruct
MEDIUM_AKASH_CHAT_API_MODEL= # Default: Meta-Llama-3-3-70B-Instruct
LARGE_AKASH_CHAT_API_MODEL=  # Default: Meta-Llama-3-1-405B-Instruct-FP8

# fal.ai Configuration
FAL_API_KEY=
FAL_AI_LORA_PATH=

# Web search API Configuration
TAVILY_API_KEY=

# WhatsApp Cloud API Configuration
WHATSAPP_ACCESS_TOKEN=         # Permanent access token from Facebook Developer Console
WHATSAPP_PHONE_NUMBER_ID=      # Phone number ID from WhatsApp Business API
WHATSAPP_BUSINESS_ACCOUNT_ID=  # Business Account ID from Facebook Business Manager
WHATSAPP_WEBHOOK_VERIFY_TOKEN= # Custom string for webhook verification
WHATSAPP_API_VERSION=v17.0     # WhatsApp API version (default: v17.0)
